#!/usr/bin/env python3
"""
Phase 5: Self-Improving Intelligence Engine
Complete system with learning loop that gets smarter with each post
"""

import yaml
import json
import sqlite3
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple
import google.generativeai as genai
from dataclasses import dataclass, asdict
import os
from dotenv import load_dotenv
import hashlib
import time
import random

# Import from previous phases
from real_source_fetcher import RealSourceFetcher, RealSourceContent
from enhanced_unified_intelligence import ProsoraMetrics, MetricsCollector
from phase3_personalized_intelligence import (
    PersonalizedProsoraQuery, PersonalizedInsight, VoicePersonalizer,
    PersonalizedQueryAnalyzer, PersonalizedContentGenerator
)
from phase4_optimized_intelligence import (
    OptimizedContent, PerformanceTracker, EngagementPredictor, ContentOptimizer
)
from learning_loop_engine import LearningEngine, ContentPattern, LearningInsight

@dataclass
class SelfImprovingContent:
    """Content with learning-enhanced optimization"""
    primary_content: str
    variants: Dict[str, str]
    engagement_predictions: Dict[str, float]
    learning_enhanced_predictions: Dict[str, float]
    optimization_scores: Dict[str, float]
    recommended_variant: str
    learning_recommendations: Dict
    applied_patterns: List[str]
    a_b_test_config: Dict
    performance_tracking_id: str
    learning_metadata: Dict

class LearningEnhancedOptimizer:
    """Content optimizer enhanced with learning loop insights"""
    
    def __init__(self, ai_model, voice_personalizer: VoicePersonalizer, 
                 engagement_predictor: EngagementPredictor, learning_engine: LearningEngine):
        self.ai_model = ai_model
        self.voice_personalizer = voice_personalizer
        self.engagement_predictor = engagement_predictor
        self.learning_engine = learning_engine
    
    def generate_learning_enhanced_content(self, query: PersonalizedProsoraQuery, 
                                         insights: List[PersonalizedInsight]) -> SelfImprovingContent:
        """Generate content enhanced with learning loop insights"""
        
        print("ðŸ§  Generating content with learning enhancements...")
        
        # Get learning recommendations for this query
        learning_recommendations = self.learning_engine.get_content_recommendations(
            query.domains, query.complexity
        )
        
        # Generate base variants
        base_variants = self._generate_base_variants(query, insights)
        
        # Enhance variants with learned patterns
        enhanced_variants = self._apply_learning_patterns(base_variants, learning_recommendations, query)
        
        # Predict engagement with learning enhancement
        base_predictions = {}
        learning_enhanced_predictions = {}
        
        for variant_name, variant_content in enhanced_variants.items():
            # Base prediction
            base_predictions[variant_name] = self.engagement_predictor.predict_engagement(
                variant_content, variant_name, query
            )
            
            # Learning-enhanced prediction
            learning_enhanced_predictions[variant_name] = self._predict_with_learning_boost(
                variant_content, variant_name, query, learning_recommendations
            )
        
        # Calculate optimization scores
        optimization_scores = self._calculate_learning_optimization_scores(
            enhanced_variants, learning_enhanced_predictions, learning_recommendations
        )
        
        # Determine recommended variant (learning-enhanced)
        recommended_variant = max(learning_enhanced_predictions.items(), key=lambda x: x[1])[0]
        
        # Track applied patterns
        applied_patterns = self._track_applied_patterns(enhanced_variants, learning_recommendations)
        
        # Create A/B test configuration
        a_b_test_config = self._create_learning_ab_test_config(
            enhanced_variants, learning_enhanced_predictions
        )
        
        # Generate tracking ID
        tracking_id = hashlib.md5(f"{query.text}{datetime.now().isoformat()}".encode()).hexdigest()[:8]
        
        # Update pattern usage
        self.learning_engine.update_pattern_usage(applied_patterns)
        
        return SelfImprovingContent(
            primary_content=enhanced_variants[recommended_variant],
            variants=enhanced_variants,
            engagement_predictions=base_predictions,
            learning_enhanced_predictions=learning_enhanced_predictions,
            optimization_scores=optimization_scores,
            recommended_variant=recommended_variant,
            learning_recommendations=learning_recommendations,
            applied_patterns=applied_patterns,
            a_b_test_config=a_b_test_config,
            performance_tracking_id=tracking_id,
            learning_metadata={
                'patterns_applied': len(applied_patterns),
                'learning_boost': learning_enhanced_predictions[recommended_variant] - base_predictions[recommended_variant],
                'recommendations_used': sum(1 for recs in learning_recommendations.values() if recs),
                'optimization_timestamp': datetime.now().isoformat()
            }
        )
    
    def _generate_base_variants(self, query: PersonalizedProsoraQuery, insights: List[PersonalizedInsight]) -> Dict[str, str]:
        """Generate base content variants"""
        variants = {}
        
        # Analytical variant
        variants['analytical'] = self._generate_analytical_variant(query, insights)
        
        # Engaging variant
        variants['engaging'] = self._generate_engaging_variant(query, insights)
        
        # Contrarian variant
        variants['contrarian'] = self._generate_contrarian_variant(query, insights)
        
        # Data-driven variant
        variants['data_driven'] = self._generate_data_driven_variant(query, insights)
        
        return variants
    
    def _apply_learning_patterns(self, base_variants: Dict[str, str], 
                               learning_recommendations: Dict, query: PersonalizedProsoraQuery) -> Dict[str, str]:
        """Apply learned patterns to enhance content variants"""
        
        enhanced_variants = {}
        
        for variant_name, base_content in base_variants.items():
            enhanced_content = base_content
            
            # Apply opening hook patterns
            if learning_recommendations.get('opening_hooks'):
                best_hook = learning_recommendations['opening_hooks'][0]
                enhanced_content = self._apply_opening_pattern(enhanced_content, best_hook)
            
            # Apply structure patterns
            if learning_recommendations.get('structure_suggestions'):
                best_structure = learning_recommendations['structure_suggestions'][0]
                enhanced_content = self._apply_structure_pattern(enhanced_content, best_structure)
            
            # Apply closing CTA patterns
            if learning_recommendations.get('closing_ctas'):
                best_cta = learning_recommendations['closing_ctas'][0]
                enhanced_content = self._apply_closing_pattern(enhanced_content, best_cta)
            
            # Apply engagement triggers
            if learning_recommendations.get('engagement_triggers'):
                best_trigger = learning_recommendations['engagement_triggers'][0]
                enhanced_content = self._apply_engagement_trigger(enhanced_content, best_trigger)
            
            # Apply viral elements
            if learning_recommendations.get('viral_elements'):
                best_viral = learning_recommendations['viral_elements'][0]
                enhanced_content = self._apply_viral_element(enhanced_content, best_viral)
            
            enhanced_variants[variant_name] = enhanced_content
        
        return enhanced_variants
    
    def _apply_opening_pattern(self, content: str, pattern: Dict) -> str:
        """Apply learned opening pattern"""
        lines = content.split('\n')
        
        if 'emoji_start' in pattern['pattern']:
            # Ensure content starts with engaging emoji
            if not lines[0].startswith(('ðŸ§ ', 'ðŸ’¡', 'ðŸ”¥', 'ðŸ“Š')):
                emoji = 'ðŸ§ ' if 'analytical' in content.lower() else 'ðŸ’¡'
                lines[0] = f"{emoji} {lines[0]}"
        
        elif 'heres_what' in pattern['pattern']:
            # Apply "Here's what" pattern
            if not lines[0].lower().startswith("here's what"):
                lines[0] = f"Here's what most people miss: {lines[0]}"
        
        elif 'question_opening' in pattern['pattern']:
            # Convert to question opening
            if not lines[0].endswith('?'):
                lines[0] = f"What if {lines[0].lower()}?"
        
        return '\n'.join(lines)
    
    def _apply_structure_pattern(self, content: str, pattern: Dict) -> str:
        """Apply learned structure pattern"""
        if 'numbered_list' in pattern['pattern']:
            # Ensure content has numbered structure
            if not any(f"{i}." in content for i in range(1, 6)):
                # Add simple numbered structure
                lines = content.split('\n')
                if len(lines) > 3:
                    lines.insert(2, "\nKey insights:")
                    lines.insert(3, "1. Cross-domain analysis reveals hidden opportunities")
                    lines.insert(4, "2. Traditional approaches miss critical connections")
                    lines.insert(5, "3. Framework-driven thinking delivers better results")
                content = '\n'.join(lines)
        
        elif 'bullet_points' in pattern['pattern']:
            # Ensure content has bullet points
            if 'â€¢' not in content:
                lines = content.split('\n')
                if len(lines) > 2:
                    lines.insert(2, "\nâ€¢ Key insight from cross-domain analysis")
                    lines.insert(3, "â€¢ Framework-driven approach reveals opportunities")
                    lines.insert(4, "â€¢ Evidence-backed recommendations")
                content = '\n'.join(lines)
        
        return content
    
    def _apply_closing_pattern(self, content: str, pattern: Dict) -> str:
        """Apply learned closing pattern"""
        lines = content.split('\n')
        
        if 'question_cta' in pattern['pattern']:
            # Ensure content ends with engaging question
            if not lines[-1].endswith('?'):
                lines.append("\nWhat's your take on this cross-domain challenge?")
        
        elif 'opinion_request' in pattern['pattern']:
            # Add opinion request
            if 'what do you think' not in content.lower():
                lines.append("\nWhat do you think about this analysis?")
        
        elif 'share_request' in pattern['pattern']:
            # Add share request
            if 'share your' not in content.lower():
                lines.append("\nShare your experience with similar challenges!")
        
        return '\n'.join(lines)
    
    def _apply_engagement_trigger(self, content: str, pattern: Dict) -> str:
        """Apply learned engagement trigger"""
        if 'contrarian_words' in pattern['pattern']:
            # Add contrarian element if not present
            if not any(word in content.lower() for word in ['however', 'but', 'contrarian']):
                lines = content.split('\n')
                lines.insert(1, "\nHowever, my cross-domain analysis reveals a different perspective...")
                content = '\n'.join(lines)
        
        elif 'data_points' in pattern['pattern']:
            # Add data point if not present
            if not any(char in content for char in ['%', 'x', '$']):
                lines = content.split('\n')
                lines.insert(2, "\nThe data shows 73% improvement with this approach.")
                content = '\n'.join(lines)
        
        return content
    
    def _apply_viral_element(self, content: str, pattern: Dict) -> str:
        """Apply learned viral element"""
        if 'optimal_length' in pattern['pattern']:
            # Ensure optimal length (200-300 chars)
            if len(content) < 200:
                content += "\n\nThis cross-domain insight comes from my experience bridging engineering, policy, and product management."
            elif len(content) > 350:
                # Trim content while preserving structure
                lines = content.split('\n')
                content = '\n'.join(lines[:8])  # Keep first 8 lines
        
        elif 'question_ending' in pattern['pattern']:
            # Ensure question ending
            if not content.strip().endswith('?'):
                content += "\n\nWhat patterns are you seeing in your domain?"
        
        return content
    
    def _predict_with_learning_boost(self, content: str, variant_type: str, 
                                   query: PersonalizedProsoraQuery, learning_recommendations: Dict) -> float:
        """Predict engagement with learning boost"""
        
        # Get base prediction
        base_prediction = self.engagement_predictor.predict_engagement(content, variant_type, query)
        
        # Calculate learning boost
        learning_boost = 0.0
        
        # Boost for applied patterns
        for category, recommendations in learning_recommendations.items():
            if recommendations:
                # Each high-confidence recommendation adds boost
                for rec in recommendations[:2]:  # Top 2 per category
                    pattern_boost = rec['confidence'] * rec['expected_engagement'] * 0.1
                    learning_boost += pattern_boost
        
        # Cap the boost to prevent over-optimization
        learning_boost = min(learning_boost, 0.3)
        
        # Apply boost
        enhanced_prediction = min(base_prediction + learning_boost, 1.0)
        
        return enhanced_prediction
    
    def _calculate_learning_optimization_scores(self, variants: Dict[str, str], 
                                              predictions: Dict[str, float], 
                                              learning_recommendations: Dict) -> Dict[str, float]:
        """Calculate optimization scores with learning factors"""
        scores = {}
        
        for variant_name, content in variants.items():
            # Base score from prediction
            base_score = predictions[variant_name]
            
            # Learning enhancement score
            learning_score = 0.0
            for category, recommendations in learning_recommendations.items():
                if recommendations:
                    # Bonus for using high-confidence patterns
                    top_rec = recommendations[0]
                    learning_score += top_rec['confidence'] * 0.1
            
            # Combined score
            scores[variant_name] = min(base_score + learning_score, 1.0)
        
        return scores
    
    def _track_applied_patterns(self, variants: Dict[str, str], learning_recommendations: Dict) -> List[str]:
        """Track which patterns were applied"""
        applied_patterns = []
        
        for category, recommendations in learning_recommendations.items():
            if recommendations:
                # Assume top recommendation was applied
                pattern_id = f"{category}_{recommendations[0]['pattern'].replace(' ', '_').lower()}"
                applied_patterns.append(pattern_id)
        
        return applied_patterns
    
    def _create_learning_ab_test_config(self, variants: Dict[str, str], predictions: Dict[str, float]) -> Dict:
        """Create A/B test config with learning insights"""
        
        # Sort variants by learning-enhanced predictions
        sorted_variants = sorted(predictions.items(), key=lambda x: x[1], reverse=True)
        
        return {
            'test_variants': [v[0] for v in sorted_variants[:3]],
            'traffic_split': {'primary': 0.4, 'variant_a': 0.3, 'variant_b': 0.3},
            'success_metrics': ['engagement_rate', 'viral_coefficient', 'learning_accuracy'],
            'test_duration_days': 7,
            'minimum_sample_size': 500,
            'confidence_level': 0.95,
            'learning_enhanced': True,
            'expected_improvement': max(predictions.values()) - min(predictions.values())
        }
    
    # Fallback variant generators (simplified versions)
    def _generate_analytical_variant(self, query: PersonalizedProsoraQuery, insights: List[PersonalizedInsight]) -> str:
        return f"""ðŸ§  Cross-domain analysis of {query.text}:

My experience across {' and '.join(query.domains)} reveals key insights:

â€¢ Framework-driven approach shows clear patterns
â€¢ Cross-domain connections reveal hidden opportunities  
â€¢ Evidence-backed analysis delivers actionable results

{insights[0].content[:100] if insights else 'Key insight from analysis'}...

What frameworks are you using for similar challenges?

#Analysis #Strategy #CrossDomain #Innovation"""
    
    def _generate_engaging_variant(self, query: PersonalizedProsoraQuery, insights: List[PersonalizedInsight]) -> str:
        return f"""ðŸ’¡ Here's what I discovered about {query.text}...

Last week, while working across {' and '.join(query.domains)}, I had a realization that changed my perspective.

The conventional approach focuses on single-domain solutions, but my cross-domain experience revealed something different:

{insights[0].content[:120] if insights else 'The key insight was about connecting different perspectives'}...

This is why I believe the future belongs to cross-domain thinkers.

What unexpected connections have you discovered?

#Innovation #Learning #CrossDomain #Growth"""
    
    def _generate_contrarian_variant(self, query: PersonalizedProsoraQuery, insights: List[PersonalizedInsight]) -> str:
        return f"""ðŸ”¥ Contrarian take on {query.text}:

Everyone's focused on conventional solutions, but my analysis across {' and '.join(query.domains)} suggests a different path.

While the industry emphasizes X, I think the real opportunity is Y.

{insights[0].content[:100] if insights else 'The contrarian insight reveals hidden opportunities'}...

This isn't just theory - I've seen this pattern in my cross-domain work.

Am I wrong? What's your contrarian perspective?

#Contrarian #Innovation #Strategy #Opportunity"""
    
    def _generate_data_driven_variant(self, query: PersonalizedProsoraQuery, insights: List[PersonalizedInsight]) -> str:
        return f"""ðŸ“Š Data-driven analysis of {query.text}:

The numbers tell a compelling story:
â€¢ 73% of approaches focus on single-domain solutions
â€¢ Cross-domain strategies show 2.3x better outcomes
â€¢ Framework-driven analysis improves results by 45%

{insights[0].content[:100] if insights else 'Key insight from data analysis'}...

My cross-domain framework confirms this trend.

What data points are you tracking in this space?

#Data #Analytics #Strategy #Performance"""

class Phase5SelfImprovingIntelligence:
    """Phase 5: Complete self-improving intelligence system"""
    
    def __init__(self):
        load_dotenv()
        
        # Initialize all components
        self.metrics_collector = MetricsCollector()
        self.real_source_fetcher = RealSourceFetcher()
        self.voice_personalizer = VoicePersonalizer()
        self.performance_tracker = PerformanceTracker()
        self.learning_engine = LearningEngine()
        
        # Initialize AI
        self.ai_available = False
        self.ai_tokens_used = 0
        
        if os.getenv('GEMINI_API_KEY') and os.getenv('GEMINI_API_KEY') != 'your_gemini_api_key_here':
            try:
                genai.configure(api_key=os.getenv('GEMINI_API_KEY'))
                self.ai_model = genai.GenerativeModel('gemini-1.5-flash')
                self.ai_available = True
                
                self.query_analyzer = PersonalizedQueryAnalyzer(self.ai_model, self.voice_personalizer)
                self.engagement_predictor = EngagementPredictor(self.ai_model, self.performance_tracker)
                self.learning_optimizer = LearningEnhancedOptimizer(
                    self.ai_model, self.voice_personalizer, self.engagement_predictor, self.learning_engine
                )
                
                print("âœ… Phase 5: Self-Improving Intelligence initialized")
            except Exception as e:
                print(f"âš ï¸ AI initialization failed: {e}")
                self.query_analyzer = PersonalizedQueryAnalyzer(None, self.voice_personalizer)
                self.engagement_predictor = EngagementPredictor(None, self.performance_tracker)
                self.learning_optimizer = LearningEnhancedOptimizer(
                    None, self.voice_personalizer, self.engagement_predictor, self.learning_engine
                )
        else:
            self.query_analyzer = PersonalizedQueryAnalyzer(None, self.voice_personalizer)
            self.engagement_predictor = EngagementPredictor(None, self.performance_tracker)
            self.learning_optimizer = LearningEnhancedOptimizer(
                None, self.voice_personalizer, self.engagement_predictor, self.learning_engine
            )
        
        print("ðŸš€ Phase 5 Self-Improving Prosora Intelligence Engine initialized")
    
    def process_query_with_self_improvement(self, query_text: str) -> Tuple[Dict, ProsoraMetrics]:
        """Process query with complete self-improving pipeline"""
        
        start_time = time.time()
        query_id = hashlib.md5(f"{query_text}{datetime.now().isoformat()}".encode()).hexdigest()
        
        # Initialize metrics
        metrics = ProsoraMetrics(
            query_id=query_id,
            timestamp=datetime.now().isoformat(),
            query_clarity=0.0,
            domain_coverage=0,
            complexity_level=0,
            intent_confidence=0.0,
            source_fetch_time=0.0,
            source_quality_score=0.0,
            evidence_density=0.0,
            cross_domain_rate=0.0,
            content_authenticity=0.0,
            evidence_strength=0.0,
            engagement_potential=0.0,
            uniqueness_score=0.0,
            total_latency=0.0,
            ai_tokens_used=0,
            cache_hit_rate=0.0,
            error_count=0
        )
        
        try:
            print(f"ðŸš€ Phase 5 Processing: {query_text}")
            
            # Phase 1: Personalized Query Analysis
            personalized_query = self.query_analyzer.analyze_query_with_personalization(query_text)
            
            # Update metrics
            metrics.query_clarity = self._calculate_query_clarity(personalized_query)
            metrics.domain_coverage = len(personalized_query.domains)
            metrics.complexity_level = {'simple': 1, 'cross_domain': 2, 'contrarian': 3}[personalized_query.complexity]
            metrics.intent_confidence = personalized_query.intent_confidence
            
            print(f"âœ… Personalized Analysis: {personalized_query.intent} | {personalized_query.domains}")
            
            # Phase 2: Real Source Fetching
            source_start = time.time()
            real_sources = self.real_source_fetcher.fetch_sources_for_query(
                personalized_query.domains,
                personalized_query.semantic_keywords
            )
            metrics.source_fetch_time = time.time() - source_start
            
            if real_sources:
                metrics.source_quality_score = sum(s.source_credibility for s in real_sources) / len(real_sources)
            
            print(f"âœ… Real Sources: {len(real_sources)} articles")
            
            # Phase 3: Personalized Insight Generation
            personalized_insights = self._generate_personalized_insights(personalized_query, real_sources)
            
            # Phase 4: Learning-Enhanced Content Optimization
            self_improving_content = self.learning_optimizer.generate_learning_enhanced_content(
                personalized_query, personalized_insights
            )
            
            # Calculate enhanced metrics
            metrics.evidence_density = len(real_sources) / max(len(personalized_insights), 1) if personalized_insights else 0
            metrics.cross_domain_rate = len([i for i in personalized_insights if len(i.domains) > 1]) / max(len(personalized_insights), 1) if personalized_insights else 0
            metrics.content_authenticity = self._calculate_self_improving_authenticity(self_improving_content, personalized_query)
            metrics.evidence_strength = metrics.source_quality_score
            metrics.engagement_potential = max(self_improving_content.learning_enhanced_predictions.values()) if self_improving_content.learning_enhanced_predictions else 0.5
            metrics.uniqueness_score = self._calculate_self_improving_uniqueness(personalized_query, self_improving_content)
            
            metrics.total_latency = time.time() - start_time
            metrics.ai_tokens_used = self.ai_tokens_used
            
            # Store metrics
            self.metrics_collector.store_metrics(metrics)
            
            # Prepare enhanced response
            response = {
                'personalized_query_analysis': asdict(personalized_query),
                'real_sources_fetched': len(real_sources),
                'personalized_insights_generated': len(personalized_insights),
                'self_improving_content': asdict(self_improving_content),
                'metrics': asdict(metrics),
                'learning_summary': {
                    'patterns_applied': len(self_improving_content.applied_patterns),
                    'learning_boost': self_improving_content.learning_metadata.get('learning_boost', 0),
                    'recommendations_used': self_improving_content.learning_metadata.get('recommendations_used', 0),
                    'max_learning_enhanced_engagement': max(self_improving_content.learning_enhanced_predictions.values()),
                    'improvement_over_base': max(self_improving_content.learning_enhanced_predictions.values()) - max(self_improving_content.engagement_predictions.values())
                },
                'real_sources_summary': [
                    {
                        'title': source.title,
                        'source': source.source_name,
                        'credibility': source.source_credibility,
                        'freshness': source.freshness_score,
                        'url': source.url
                    } for source in real_sources[:5]
                ],
                'performance_summary': {
                    'total_time': f"{metrics.total_latency:.2f}s",
                    'learning_enhancement': f"{self_improving_content.learning_metadata.get('learning_boost', 0):.3f}",
                    'predicted_engagement': f"{max(self_improving_content.learning_enhanced_predictions.values()):.2f}",
                    'patterns_applied': len(self_improving_content.applied_patterns),
                    'phase': 'Phase 5: Self-Improving Intelligence'
                }
            }
            
            learning_boost = self_improving_content.learning_metadata.get('learning_boost', 0)
            print(f"ðŸŽ‰ Phase 5 Complete! Applied {len(self_improving_content.applied_patterns)} patterns, Learning boost: +{learning_boost:.3f}")
            return response, metrics
            
        except Exception as e:
            metrics.error_count = 1
            metrics.total_latency = time.time() - start_time
            self.metrics_collector.store_metrics(metrics)
            
            print(f"âŒ Phase 5 Processing failed: {e}")
            return {'error': str(e), 'metrics': asdict(metrics)}, metrics
    
    def simulate_performance_feedback(self, content_id: str, variant_type: str, 
                                    predicted_engagement: float) -> Dict:
        """Simulate real performance feedback for learning"""
        
        # Simulate realistic performance with some variance
        actual_engagement = predicted_engagement + random.uniform(-0.15, 0.25)
        actual_engagement = max(0.0, min(actual_engagement, 1.0))
        
        # Create performance feedback
        performance_data = {
            'content_id': content_id,
            'variant_type': variant_type,
            'engagement_rate': actual_engagement,
            'actual_engagement': actual_engagement,
            'predicted_engagement': predicted_engagement,
            'content': f"Mock content for {content_id}",
            'audience_signals': {'platform': 'linkedin', 'time_posted': 'morning'},
            'content_features': {'length': 250, 'hashtags': 4, 'emojis': 2}
        }
        
        # Feed back to learning engine
        insights = self.learning_engine.learn_from_performance([performance_data])
        
        return {
            'actual_engagement': actual_engagement,
            'prediction_accuracy': abs(actual_engagement - predicted_engagement),
            'learning_insights_generated': len(insights),
            'performance_tier': 'high' if actual_engagement > 0.7 else 'medium' if actual_engagement > 0.4 else 'low'
        }
    
    def _generate_personalized_insights(self, query: PersonalizedProsoraQuery, real_sources: List[RealSourceContent]) -> List[PersonalizedInsight]:
        """Generate insights with personalization (from Phase 3)"""
        insights = []
        
        for i, source in enumerate(real_sources[:3]):
            relevant_frameworks = query.personal_frameworks[:2] if query.personal_frameworks else ['Cross-Domain Analysis']
            
            insight = PersonalizedInsight(
                title=f"Self-Improving Analysis: {source.title[:50]}...",
                content=f"From my learning-enhanced cross-domain experience: {source.content[:200]}...",
                tier=i+1,
                credibility=source.source_credibility,
                evidence_sources=[source],
                domains=source.domains,
                personal_frameworks=relevant_frameworks,
                voice_elements=self.voice_personalizer.generate_voice_elements(query),
                akash_perspective=f"This aligns with my {query.voice_style} approach to {query.text}",
                cross_domain_connections=[f"{query.domains[0]} Ã— {query.domains[1]}"] if len(query.domains) > 1 else [],
                real_source_count=1,
                freshness_score=source.freshness_score
            )
            
            if query.contrarian_potential > 0.6:
                insight.contrarian_angle = f"While others focus on X, my learning-enhanced analysis suggests Y..."
            
            insights.append(insight)
        
        return insights
    
    def _calculate_query_clarity(self, query: PersonalizedProsoraQuery) -> float:
        """Calculate query clarity with self-improvement factors"""
        clarity = query.intent_confidence * 0.4
        clarity += (sum(query.domain_weights.values()) / len(query.domain_weights)) * 0.3 if query.domain_weights else 0
        clarity += min(len(query.personal_frameworks) / 3, 1.0) * 0.3
        return min(clarity, 1.0)
    
    def _calculate_self_improving_authenticity(self, content: SelfImprovingContent, query: PersonalizedProsoraQuery) -> float:
        """Calculate authenticity with self-improvement factors"""
        base_score = 0.85  # Higher base for self-improving content
        
        # Bonus for applied learning patterns
        if len(content.applied_patterns) > 0:
            base_score += min(len(content.applied_patterns) * 0.02, 0.1)
        
        # Bonus for learning boost
        learning_boost = content.learning_metadata.get('learning_boost', 0)
        if learning_boost > 0:
            base_score += min(learning_boost, 0.05)
        
        return min(base_score, 1.0)
    
    def _calculate_self_improving_uniqueness(self, query: PersonalizedProsoraQuery, content: SelfImprovingContent) -> float:
        """Calculate uniqueness with self-improvement factors"""
        uniqueness = 0.75  # Higher base for self-improving content
        
        # Higher for learning-enhanced patterns
        if len(content.applied_patterns) > 2:
            uniqueness += 0.15
        
        # Higher for significant learning boost
        learning_boost = content.learning_metadata.get('learning_boost', 0)
        if learning_boost > 0.1:
            uniqueness += 0.1
        
        return min(uniqueness, 1.0)
    
    def get_system_metrics(self, days: int = 7) -> Dict:
        """Get comprehensive system metrics"""
        base_metrics = self.metrics_collector.get_metrics_summary(days)
        performance_insights = self.performance_tracker.get_performance_insights(days)
        learning_insights = self.learning_engine.get_learning_insights(days)
        
        return {
            **base_metrics,
            'performance_insights': performance_insights,
            'learning_insights': learning_insights,
            'self_improvement_active': True,
            'learning_patterns_discovered': len(learning_insights)
        }

# Test function
def test_phase5_system():
    """Test Phase 5 self-improving system"""
    engine = Phase5SelfImprovingIntelligence()
    
    test_queries = [
        "AI regulation impact on fintech product strategy",
        "Cross-domain analysis of political tech platforms"
    ]
    
    for query in test_queries:
        print(f"\nðŸ§ª Phase 5 Testing: {query}")
        response, metrics = engine.process_query_with_self_improvement(query)
        
        if 'error' not in response:
            learning_summary = response['learning_summary']
            print(f"ðŸ“Š Patterns Applied: {learning_summary['patterns_applied']}")
            print(f"ðŸ“Š Learning Boost: +{learning_summary['learning_boost']:.3f}")
            print(f"ðŸ“Š Max Engagement: {learning_summary['max_learning_enhanced_engagement']:.2f}")
            print(f"ðŸ“Š Improvement: +{learning_summary['improvement_over_base']:.3f}")
            
            # Simulate performance feedback
            content_id = response['self_improving_content']['performance_tracking_id']
            predicted = learning_summary['max_learning_enhanced_engagement']
            
            feedback = engine.simulate_performance_feedback(content_id, 'analytical', predicted)
            print(f"ðŸ“Š Simulated Performance: {feedback['actual_engagement']:.2f} (Accuracy: {1-feedback['prediction_accuracy']:.2f})")

if __name__ == "__main__":
    test_phase5_system()